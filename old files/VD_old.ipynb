{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Download multiple DATE x VDID loop\n","## Set parameters."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T06:00:41.185877Z","iopub.status.busy":"2023-04-24T06:00:41.185419Z","iopub.status.idle":"2023-04-24T06:00:41.193119Z","shell.execute_reply":"2023-04-24T06:00:41.191579Z","shell.execute_reply.started":"2023-04-24T06:00:41.185830Z"},"trusted":true},"outputs":[],"source":["#***********************************************************************\n","clear_working_folder = True # so you will only be mailed with the latest results, but make sure the files have been saved.\n","use_all_subfolders = False # if this is true, then you can only use Kaggle dataset.\n","realtime = True #will be set to false if you use all subfolders\n","use_yesterday = True # if true, the date_list will be changed to yesterday for scheduled runs.\n","\n","dataset_list = ['vd-2023-0326-0401'] # If the length of this list is longer than one, use_all_subfolders == True, realtime == False.\n","date_list = ['20230401']#[yesterday_str] if you want to run data from yesterday\n","#vdid_list = [\"VD-N1-S-369.007-M-Loop\", \"VD-N1-S-369.400-M-Loop\", \"VD-N1-S-370.000-M-Loop\", \"VD-N1-S-371.010-M-Loop\"]\n","#vdid_list = [\"VD-N1-S-370.000-M-Loop\", \"VD-N1-S-371.010-M-Loop\"]\n","vdid_list = ['VD-N5-N-15.488-M-LOOP']#, 'VD-N5-N-16.196-M-LOOP', 'VD-N5-N-19.012-M-LOOP', 'VD-N5-N-27.468-M-LOOP', 'VD-N5-N-27.779-M-LOOP']\n","start_time = \"0000\"\n","end_time = \"0600\"\n","\n","your_email = 'tudo11927.y@nycu.edu.tw'\n","#***********************************************************************"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load the dataset and the packages\n","* Suggest uploading the xml.gz files onto Kaggle so it doesn't fuck up the output storage.\n","* Also, the package xmltodict have to be installed before anything happens."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T05:58:35.503310Z","iopub.status.busy":"2023-04-24T05:58:35.502920Z","iopub.status.idle":"2023-04-24T05:58:47.073596Z","shell.execute_reply":"2023-04-24T05:58:47.071949Z","shell.execute_reply.started":"2023-04-24T05:58:35.503273Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xmltodict in c:\\users\\galen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install xmltodict \n","# Install xmltodict package if not already installed\n","\n","import xmltodict # Import xmltodict module for parsing XML data\n","import numpy as np # Import numpy and pandas for data analysis and processing\n","import pandas as pd\n","import json # Import json module for working with JSON data\n","from tqdm import tqdm # Import tqdm module for progress bars\n","import urllib.request # Import urllib.request module for working with URLs\n","import gzip # Import gzip module for working with compressed data files\n","from datetime import datetime, timedelta \n","import pytz # Import datetime and pytz modules for working with dates and times\n","import os # Import os module for working with the file system\n","\n","# Walk through the /kaggle/input directory and print out the path of each file in it\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","    #for filename in filenames:\n","        #print(os.path.join(dirname, filename))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Realtime downloading and conversion pipeline\n","\n","Download xml.gz file, decompress into xml file, then delete the xml.gz, then feed the xml into get_vd, then delete the xml after data is analyzed."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T05:58:47.076085Z","iopub.status.busy":"2023-04-24T05:58:47.075659Z","iopub.status.idle":"2023-04-24T05:58:47.090843Z","shell.execute_reply":"2023-04-24T05:58:47.089538Z","shell.execute_reply.started":"2023-04-24T05:58:47.076028Z"},"trusted":true},"outputs":[],"source":["def download_xml(date, current_time):\n","    \n","    global file_exist\n","    global empty_file\n","    \n","    file_exist = False\n","    empty_file = False\n","\n","    url = f'https://tisvcloud.freeway.gov.tw/history/motc20/VD/{date}/VDLive_{current_time}.xml.gz'\n","    filename = f'VDLive_{current_time}.xml.gz'\n","\n","    # Download the file\n","    if os.path.isfile(filename):\n","        if os.path.getsize(filename) > 0 and os.path.getsize(filename) < 1024:\n","            os.remove(filename)\n","            empty_file = True\n","            file_exist = True\n","        elif os.path.getsize(filename) == 0:\n","            os.remove(filename)\n","            file_exist = False\n","        else: file_exist = True\n","    else:\n","        urllib.request.urlretrieve(url, filename)\n","        if urllib.request.urlopen(url).getcode() == 404:\n","            file_exist = False\n","            os.remove(filename)\n","            return\n","        elif os.path.getsize(filename) > 0 and os.path.getsize(filename) < 1024:\n","            os.remove(filename)\n","            empty_file = True\n","            file_exist = True\n","            return\n","        elif os.path.getsize(filename) == 0:\n","            os.remove(filename)\n","            file_exist = False\n","            return\n","        else: file_exist = True\n","\n","    if file_exist and not empty_file:\n","        # File decompression\n","        if os.path.isfile(filename):\n","            with gzip.open(filename, 'rb') as f:\n","                xml_data = f.read()\n","\n","            xml_file_path = f'C:\\\\Users\\\\galen\\\\Downloads\\\\VD_data\\\\VDLive_{current_time}.xml'\n","\n","            with open(xml_file_path, 'wb') as f:\n","                f.write(xml_data)\n","\n","            if os.path.exists(xml_file_path):\n","                os.remove(filename)\n","            else:\n","                print(f'Error: {xml_file_path} was not created.')\n","        else:\n","            print(f\"Error: {filename} not found.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## XML to JSON to DataFrame with pivoting to CSV pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T05:58:47.095125Z","iopub.status.busy":"2023-04-24T05:58:47.094388Z","iopub.status.idle":"2023-04-24T05:58:47.129229Z","shell.execute_reply":"2023-04-24T05:58:47.128150Z","shell.execute_reply.started":"2023-04-24T05:58:47.095069Z"},"trusted":true},"outputs":[],"source":["def get_vd(date, time, desired_vdid, realtime, dataset):\n","\n","    global vdid_found\n","    global vdid_absent\n","    vdid_found = False\n","    \n","\n","    if realtime:\n","        directory = f'C:\\\\Users\\\\galen\\\\Downloads\\\\VD_data\\\\VDLive_{time}.xml'\n","    else:\n","        global file_exist\n","        global empty_file\n","        global file_absent_in_dataset\n","        empty_file = False\n","        file_exist = False\n","        directory = f\"/kaggle/input/{dataset}/{date}/kaggle/working/{date}/VDLive_{time}.xml/VDLive_{time}.xml\"\n","        if not os.path.isfile(directory):\n","            file_absent_in_dataset.append(time)\n","            return\n","\n","        elif os.path.getsize(directory) > 0 and os.path.getsize(directory) < 1024:\n","            empty_file = True\n","            file_exist = True\n","            return\n","        elif os.path.getsize(directory) == 0:\n","            file_exist = False\n","            return\n","        else:\n","            file_exist = True\n","    #print(file_exist, empty_file)\n","    \n","    if file_exist and not empty_file:\n","        with open(directory) as xml_file:   # Parse XML data into a dictionary\n","            data_dict = xmltodict.parse(xml_file.read())\n","        json_data = json.dumps(data_dict) # Convert dictionary to JSON\n","        #print(\"XML file converted to JSON.\")    \n","        data = json.loads(json_data) # Load the JSON data into a dictionary\n","        #print(data)\n","        # Get the desired VDID, and iterate through the VDLives and find the one with the desired VDID\n","        for vdlive in data[\"VDLiveList\"][\"VDLives\"][\"VDLive\"]:\n","            if vdlive[\"VDID\"] == desired_vdid:\n","                # Extract the data for the desired VDID\n","                link_flows = vdlive[\"LinkFlows\"][\"LinkFlow\"]\n","                status = vdlive[\"Status\"]\n","                date_time = f'{date}_{time}'\n","                # Print the VDID and its corresponding data\n","                data= {\"VDID\": desired_vdid, \"LinkFlows\": link_flows, \"Status\": status,\n","                       #\"DateTime\": date_time\n","                      }\n","                #print(f\"Detector {desired_vdid} found.\")\n","                #print(data)\n","                vdid_found = True\n","                break\n","\n","        if vdid_found:\n","            # Extract data from JSON and flatten into a list of rows\n","            rows = []\n","            vdid = data['VDID']\n","            date_time = f'{date}_{time}'\n","            link_id = data['LinkFlows']['LinkID']\n","\n","            # Situation 1: 'Lane' key is present in the 'Lanes' dictionary\n","            if 'Lane' in data['LinkFlows']['Lanes']:\n","                lanes = data['LinkFlows']['Lanes']['Lane']\n","                if isinstance(lanes, dict):\n","                    # If 'Lane' is a dictionary, convert it to a list with a single element\n","                    lanes = [lanes]\n","                for lane in lanes:\n","                    lane_id = lane['LaneID']\n","                    lane_type = lane['LaneType']\n","                    lane_speed = lane['Speed']\n","                    occupancy = lane['Occupancy']\n","                    for vehicle in lane['Vehicles']['Vehicle']:\n","                        vehicle_type = vehicle['VehicleType']\n","                        volume = vehicle['Volume']\n","                        speed = vehicle['Speed']\n","                        rows.append([date_time, vdid, link_id, lane_id,\n","                                     lane_type, lane_speed, occupancy, \n","                                     vehicle_type, volume, speed])\n","\n","            # Situation 2: 'Lane' key is not present in the 'Lanes' dictionary\n","            elif 'Lane' in data['LinkFlows']['Lanes']['Lane']:\n","                lane = data['LinkFlows']['Lanes']['Lane']\n","                lane_id = lane['LaneID']\n","                lane_type = lane['LaneType']\n","                lane_speed = lane['Speed']\n","                occupancy = lane['Occupancy']\n","                for vehicle in lane['Vehicles']['Vehicle']:\n","                    vehicle_type = vehicle['VehicleType']\n","                    volume = vehicle['Volume']\n","                    speed = vehicle['Speed']\n","                    rows.append([date_time, vdid, link_id, lane_id,\n","                                 lane_type, lane_speed, occupancy,\n","                                 vehicle_type, volume, speed])\n","            return rows\n","        else:\n","            vdid_absent.append(str(time))\n","\n","\n","def get_vds(date, desired_vdid, start_time, end_time, realtime, dataset):\n","    \n","    global email_text\n","    global vdid_absent\n","\n","    # Convert start_time and end_time to integers\n","    start_time2 = int(start_time)\n","    str_end_time = end_time\n","    end_time = int(end_time)\n","\n","    # Convert start_time and end_time to minutes\n","    start_time_minutes = (start_time2 // 100) * 60 + (start_time2 % 100)\n","    end_time_minutes = (end_time // 100) * 60 + (end_time % 100)\n","    total = end_time_minutes - start_time_minutes + 1\n","\n","    # Create an empty list to store the results\n","    results = []\n","    missing = []\n","    empty_files =[]\n","    file_absent_in_dataset =[]\n","    vdid_absent = []\n","    \n","    i = 0\n","    current_time = start_time\n","\n","    # Loop through the function multiple times and append the result to the list\n","    with tqdm(total=total) as pbar:\n","        while i < total:\n","            \n","            if realtime == True:\n","                download_xml(date, current_time)\n","            result = get_vd(date, current_time, desired_vdid, realtime, dataset) ###\n","            if vdid_found == True:\n","                results.extend(result)\n","            filename = f\"C:\\\\Users\\\\galen\\\\Downloads\\\\VD_data\\\\VDLive_{current_time}.xml\"\n","            #if os.path.exists(filename):\n","                #os.remove(filename)               \n","            if empty_file:\n","                empty_files.append(str(current_time))\n","            if not file_exist:\n","                missing.append(str(current_time))\n","                \n","            pbar.update(1)\n","            i += 1\n","\n","            if int(current_time) % 100 == 59:\n","                current_time = str(int(current_time)+41)\n","            else:\n","                current_time = str(int(current_time)+1)\n","            \n","            if int(current_time)<10:\n","                current_time = f\"000{current_time}\"\n","            elif int(current_time)<100:\n","                current_time = f\"00{current_time}\"\n","            elif int(current_time)<1000:\n","                current_time = f\"0{current_time}\"\n","            else:\n","                current_time = current_time\n","\n","    #print(results)\n","\n","    # Create a pandas DataFrame from the rows list\n","    df = pd.DataFrame(results, columns=['DateTime', 'VDID', 'LinkID',\n","                                        'LaneID', 'LaneType',\n","                                        'LaneSpeed', 'Occupancy',\n","                                        'VehicleType', 'Volume', 'Speed'])\n","    #pivot dataframe according to vehicle\n","    df = df.pivot(index=['DateTime', 'VDID', 'LinkID', 'LaneID',\n","                     'LaneType', 'LaneSpeed', 'Occupancy'],\n","              columns='VehicleType',\n","              values=['Volume', 'Speed'])\n","    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n","    df = df.reset_index()\n","    df = df.reindex(columns=['DateTime', 'VDID', #'LinkID', \n","                             'LaneID',#'LaneType',\n","                             'LaneSpeed', 'Occupancy',\n","                             'Volume_S', 'Speed_S', 'Volume_L', 'Speed_L', 'Volume_T', 'Speed_T'])\n","    \n","    #pivot the dataframe according to lane\n","    df = df.pivot_table(index=['DateTime', 'VDID'], columns='LaneID', values=['LaneSpeed', 'Occupancy', 'Volume_S', 'Speed_S', 'Volume_L', 'Speed_L', 'Volume_T', 'Speed_T']).reset_index()\n","    #flatten the column names\n","    df.columns = ['_'.join(str(col).strip() for col in tup) for tup in df.columns.values]\n","\n","    #Save to CSV\n","    filename = f'{date}_{desired_vdid}_{start_time}_{str_end_time}'\n","    df.to_csv(f'{filename}.csv', index=False)\n","    \n","    \n","    report_string = (f\"{filename}.csv has been saved in /kaggle/working.\\n\"\n","      f\"missing files = {missing}\\n\"\n","      f\"files not found in dataset = {file_absent_in_dataset}\\n\"\n","      f\"empty files = {empty_files}\\n\"\n","      f\"VDID not found in files = {vdid_absent}\\n\"\n","      f\"\\n\")\n","    \n","    # Append the report string to the email text using a list\n","    email_text += report_string\n","    \n","    print(report_string)\n","    #display(df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Acquire time so the script does automatic daily updates for yesterday."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T05:58:47.130991Z","iopub.status.busy":"2023-04-24T05:58:47.130624Z","iopub.status.idle":"2023-04-24T05:58:47.147529Z","shell.execute_reply":"2023-04-24T05:58:47.146244Z","shell.execute_reply.started":"2023-04-24T05:58:47.130952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["20230630\n"]}],"source":["# Set the time zone to GMT+8\n","tz = pytz.timezone('Asia/Taipei')\n","# Get the current time in GMT+8 time zone\n","now = datetime.now(tz)\n","# Subtract one day to get yesterday's date\n","yesterday = now - timedelta(days=1)\n","# Format yesterday's date as YYYYMMDD\n","yesterday_str = yesterday.strftime('%Y%m%d')\n","\n","if use_yesterday== True:\n","    date_list = [yesterday_str]\n","\n","print(yesterday_str)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Mail execution results and data to the user with Gmail API."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T05:58:47.150020Z","iopub.status.busy":"2023-04-24T05:58:47.148887Z","iopub.status.idle":"2023-04-24T05:58:47.162218Z","shell.execute_reply":"2023-04-24T05:58:47.160776Z","shell.execute_reply.started":"2023-04-24T05:58:47.149965Z"},"trusted":true},"outputs":[],"source":["import smtplib\n","import os\n","from email.mime.text import MIMEText\n","from email.mime.multipart import MIMEMultipart\n","from email.mime.application import MIMEApplication\n","\n","def email_report(your_email):\n","\n","    ## Gmail account credentials\n","    gmail_user = 'galen147258369@gmail.com'\n","    gmail_password = 'ikikvtbtlecywjtt'\n","\n","    # Recipient email address\n","    to = your_email\n","\n","    # Create a multipart message container\n","    msg = MIMEMultipart()\n","\n","    # Set the subject of the email\n","    msg['Subject'] = 'Taiwan Highway VD project'\n","\n","    # Set the sender and recipient of the email\n","    msg['From'] = gmail_user\n","    msg['To'] = to\n","\n","    # Create a text message part\n","    text = MIMEText(email_text)\n","    msg.attach(text)\n","\n","    # Attach all files in the working directory to the email\n","    working_dir = '/kaggle/working/'\n","    file_list = [f for f in os.listdir(working_dir) if not f.startswith('.virtual_documents') and os.path.isfile(os.path.join(working_dir, f))]\n","    for filename in file_list:\n","        file_path = os.path.join(working_dir, filename)\n","        with open(file_path, 'rb') as f:\n","            file_data = f.read()\n","        attachment = MIMEApplication(file_data, _subtype='csv')\n","        attachment.add_header('content-disposition', 'attachment', filename=filename)\n","        msg.attach(attachment)\n","\n","    # Connect to Gmail's SMTP server and send the email\n","    server = smtplib.SMTP('smtp.gmail.com', 587)\n","    server.ehlo()\n","    server.starttls()\n","    server.login(gmail_user, gmail_password)\n","    server.sendmail(msg['From'], msg['To'], msg.as_string())\n","    server.quit()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# RUN THE CODE HERE !"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-24T05:58:47.164485Z","iopub.status.busy":"2023-04-24T05:58:47.164064Z","iopub.status.idle":"2023-04-24T06:00:12.368232Z","shell.execute_reply":"2023-04-24T06:00:12.366819Z","shell.execute_reply.started":"2023-04-24T05:58:47.164446Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["'rm' is not recognized as an internal or external command,\n","operable program or batch file.\n"]},{"name":"stdout","output_type":"stream","text":["Dataset list: ['vd-2023-0326-0401']\n","Use all subfolders: False\n","Date list: ['20230630']\n","VDID list: ['VD-N5-N-15.488-M-LOOP']\n","Start time: 0000\n","End time: 0600\n","Realtime: True\n","Your email: tudo11927.y@nycu.edu.tw\n","\n","\n"," Total tasks: 1\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/361 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 361/361 [14:15<00:00,  2.37s/it]\n"]},{"name":"stdout","output_type":"stream","text":["20230630_VD-N5-N-15.488-M-LOOP_0000_0600.csv has been saved in /kaggle/working.\n","missing files = []\n","files not found in dataset = []\n","empty files = []\n","VDID not found in files = []\n","\n","\n"]},{"ename":"FileNotFoundError","evalue":"[WinError 3] The system cannot find the path specified: '/kaggle/working/'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m email_text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[39m# Get a list of all files in the /kaggle/working/ directory excluding '.virtual_documents' directory\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m file_list \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m/kaggle/working/\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m.virtual_documents\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m/kaggle/working/\u001b[39m\u001b[39m'\u001b[39m, f))]\n\u001b[0;32m     74\u001b[0m \u001b[39m# Add the list of files to email_text\u001b[39;00m\n\u001b[0;32m     75\u001b[0m email_text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttachment: \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m file_list]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/kaggle/working/'"]}],"source":["if clear_working_folder == True:\n","    !rm -rf /kaggle/working/*\n","    \n","if len(dataset_list) > 1:\n","    use_all_subfolders == True\n","    realtime == False\n","\n","file_exist = False\n","empty_file = False\n","vdid_found = False\n","file_absent_in_dataset = []\n","vdid_absent = []\n","email_text = \"\"\n","task = 0\n","\n","report_string = \"Dataset list: \" + str(dataset_list) + \"\\n\"\n","report_string += \"Use all subfolders: \" + str(use_all_subfolders) + \"\\n\"\n","report_string += \"Date list: \" + str(date_list) + \"\\n\"\n","report_string += \"VDID list: \" + str(vdid_list) + \"\\n\"\n","report_string += \"Start time: \" + start_time + \"\\n\"\n","report_string += \"End time: \" + end_time + \"\\n\"\n","report_string += \"Realtime: \" + str(realtime) + \"\\n\"\n","report_string += \"Your email: \" + your_email + \"\\n\"\n","report_string += \"\\n\"\n","\n","print(report_string)\n","\n","email_text += report_string\n","\n","total_tasks = 0\n","\n","if use_all_subfolders:\n","    subfolders = []\n","    for dataset in dataset_list:\n","        for folder_name in os.listdir(f'/kaggle/input/{dataset}'):\n","            if os.path.isdir(os.path.join(f'/kaggle/input/{dataset}', folder_name)):\n","                subfolders.append(folder_name)\n","        date_list = subfolders\n","        total_tasks += len(date_list)*len(vdid_list)\n","else:\n","    total_tasks = len(date_list)*len(vdid_list)\n","    \n","print(f' Total tasks: {total_tasks}')\n","print()\n","\n","task = 0\n","\n","if use_all_subfolders:\n","    realtime = False # if use all subfolders, then realtime must be false.\n","    for dataset in dataset_list:\n","        subfolders = []\n","        for folder_name in os.listdir(f'/kaggle/input/{dataset}'):\n","            if os.path.isdir(os.path.join(f'/kaggle/input/{dataset}', folder_name)):\n","                subfolders.append(folder_name)\n","        date_list = subfolders\n","        for date in date_list:\n","            for vdid in vdid_list:\n","                get_vds(date, vdid, start_time, end_time, realtime, dataset)\n","                task += 1\n","else:\n","    for date in date_list:\n","        for vdid in vdid_list:\n","            get_vds(date, vdid, start_time, end_time, realtime, dataset_list[0])\n","            task += 1\n","\n","loop_complete = f\"{task} out of {total_tasks} tasks in the loop were completed.\"\n","\n","email_text +=loop_complete\n","email_text += \"\\n\"\n","email_text += \"\\n\"\n","\n","# Get a list of all files in the /kaggle/working/ directory excluding '.virtual_documents' directory\n","file_list = [f for f in os.listdir('/kaggle/working/') if not f.startswith('.virtual_documents') and os.path.isfile(os.path.join('/kaggle/working/', f))]\n","# Add the list of files to email_text\n","email_text += \"\\n\".join([f\"Attachment: {filename}\" for filename in file_list]) + \"\\n\"\n","\n","email_text += \"\\n\"\n","email_text += \"END OF MESSAGE\"\n","\n","email_report(your_email)\n","print(\"Email sent.\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
